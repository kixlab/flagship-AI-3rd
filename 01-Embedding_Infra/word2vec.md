# Word2Vec Implementation (skip-gram)

## Process
1. Refine data from the raw data (paragraphs -> sentences of words)
2. Break sentence into words (Morpheme analyzer may be needed)
3. Create training dataset (ex. create skip-gram set)
4. Train model with the dataset
5. Check accuracy of the model

## Refining Data

## Getting words from the Data

## Creating Training Dataset

### Creating skip-grams

### 

## Training Model

## Testing the Model

### t-SNE (t-Stochastcic Neighbor Embedding)
Used for dimensionality reduction & visualization; Normally used for word2vec.

SNE + Solving Crowding Problem => t-SNE

## References

- [t-SNE](https://ratsgo.github.io/machine%20learning/2017/04/28/tSNE/)